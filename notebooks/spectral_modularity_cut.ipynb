{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Modularity Cut\n",
    "\n",
    "The purpose of this tutorial is to explore the spectral cut method for partitioning a network into two communities. The problem to be solved is to partition the vertices of a network in such a way that the modularity metric is maximized. In class, we observed that it is not computationally practical to search through all possible ways of partitioning nodes into two classes (or _shores_ as they were described in class), so we have to find ways to approximate the optimal solution. \n",
    "\n",
    "The spectral cut method seeks to find a partition into two classes that maximizes the modularity metric\n",
    "\n",
    "$$ Q({\\rm partition}) = \\frac{1}{2m} \\sum_{i,j\\in V} \\left[A_{i,j} - \\frac{k_ik_j}{2m}\\right] \\delta_(c_i,c_j) $$\n",
    "\n",
    "The _modularity matrix_ was defined using the core part of the definition of the modularity metric,\n",
    "\n",
    "$$ B_{ij} = A_{ij} - \\frac{k_ik_j}{2m}$$\n",
    "\n",
    "In matrix form, the modularity matrix is therefore defined as\n",
    "\n",
    "$$ B = A - {\\mathbf k}{\\mathbf k}^T $$\n",
    "\n",
    "where ${\\mathbf k}$ is the column vector made up of the degrees of each vertex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to turn the maximization problem into an eigenvalue problem by\n",
    "- changing the $\\delta$ function in the modularity metric into a function that assigned each vertex to a positive shore (with value $+1$) and a negative shore (with value $-1$)\n",
    "- allowing values other than $+1$ and $-1$\n",
    "- adding a constraint on the values\n",
    "- formulating a Lagrange multiplier problem\n",
    "- taking the derivative of the Lagrange multiple equation, setting it to zero, and solving\n",
    "\n",
    "These steps are summarized as\n",
    "\n",
    "$$ \\begin{array}{rcl}\n",
    "    {\\rm maximize} & Q({\\rm partition}) & \\Rightarrow \\\\\n",
    "    {\\rm maximize} & {\\mathbf x}^T B {\\mathbf x} & \\Rightarrow \\\\\n",
    "    {\\rm solve} & B{\\mathbf x} = \\lambda{\\mathbf x}\n",
    "\\end{array} $$\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leading Eigenvalue**\n",
    "\n",
    "Which eigenvector maximizes ${\\mathbf x}^T B {\\mathbf x}$? Observe that since ${\\mathbf x}$ and $\\lambda$ are solutions of to the eigenvalue equation $B{\\mathbf x} = \\lambda{\\mathbf x}$, we can write  \n",
    "\n",
    "$$ \\begin{array}{rcl}\n",
    "{\\mathbf x}^T B {\\mathbf x} &=& {\\mathbf x}^T \\big(B {\\mathbf x}\\big) \\\\\n",
    "&=& {\\mathbf x}^T \\big(\\lambda {\\mathbf x}\\big) \\\\\n",
    "&=& \\lambda {\\mathbf x}^T {\\mathbf x}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The last line of these equations shows that the modularity is maximized when we choose the largest value of $\\lambda$ and its corresponding eigenvecteor. The eigenvector corresponding to the largest eigenvalue is called the _leading eigenvector_.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will explore what the algorithm does and explain how the eigenvector used in the spectral cut algorithm differs from the other eigenvector problem we've seen, namey the eigenvector centrality problem. \n",
    "\n",
    "As usual, we'll begin by defining some visualization functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "from typing import Hashable, Tuple, Set, List\n",
    "\n",
    "def get_NCM_Figure3_14() -> Tuple[nx.Graph, dict[Hashable, Tuple[float, float]]]:\n",
    "    \"\"\"\n",
    "        Figure 3.14 from the book Networks, Crowds, and Markets is a useful\n",
    "        example graph. This function returns this figure as a networkx Graph\n",
    "        and a position dictionary for the neato layout\n",
    "    \"\"\"\n",
    "    G: nx.Graph = nx.Graph()\n",
    "    G.add_nodes_from(range(0,14))\n",
    "    G.add_edges_from([(0,1),(0,2),(1,2),(3,4),(3,5),(4,5),(8,9),(8,10),(9,10),(11,12),(11,13),(12,13),(2,6),(5,6),(7,8),(7,11),(6,7)])\n",
    "    pos: dict[Hashable, Tuple[float, float]] = nx.nx_pydot.graphviz_layout(G,prog='neato')\n",
    "    return G, pos\n",
    "\n",
    "def draw_edge_by_type(G: nx.Graph, \n",
    "                      pos: dict[Hashable, Tuple[float, float]], \n",
    "                      edge: Tuple[Hashable, Hashable], \n",
    "                      partition: Tuple[Set, ...]\n",
    "                      ) -> None:\n",
    "    \"\"\"\n",
    "        Draw edges between nodes in different partitions using dashed lines.\n",
    "        Draw edges between nodes within the same partition using solid lines.\n",
    "    \"\"\"\n",
    "    edge_style = 'dashed'\n",
    "    for part in partition:\n",
    "        if edge[0] in part and edge[1] in part:\n",
    "            edge_style = 'solid'\n",
    "            break\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=[edge], style = edge_style)\n",
    "\n",
    "def show_partitions(G: nx.Graph,\n",
    "                    partition: Tuple[Set, ...], \n",
    "                    pos: dict[Hashable, Tuple[float, float]] | None = None,\n",
    "                    title = \"\"\n",
    "                    ) -> None:\n",
    "    \"\"\" \n",
    "        Show the networkx graph with colors and edges indicating properties\n",
    "        of the partition\n",
    "\n",
    "        Edges:\n",
    "        • Dashed lines indicate edges between nodes in different partitions\n",
    "        • Solid lines indicate edges between nodes in the same partition\n",
    "\n",
    "        Nodes:\n",
    "        • All nodes in the same partition get mapped to the same color\n",
    "        • When there are more partitions than ther are in the color pallette, repeat colors\n",
    "    \"\"\"\n",
    "    #color_list = ['c','m','y','g','r']\n",
    "    color_list: list[str] = ['y', 'lightblue', 'violet', 'salmon', \n",
    "                         'aquamarine', 'lightpink', 'lightgray', 'linen']\n",
    "    plt.clf()\n",
    "    ax: Axes = plt.gca()\n",
    "    if pos is None: \n",
    "        pos = nx.spring_layout(G, seed = 0)\n",
    "    for i in range(len(partition)):\n",
    "        nx.draw_networkx_nodes(partition[i],pos,node_color=color_list[i%len(color_list)], alpha = 0.8)\n",
    "    for edge in G.edges:\n",
    "        draw_edge_by_type(G, pos, edge, partition)\n",
    "    nx.draw_networkx_labels(G,pos)\n",
    "    if len(G.edges) == 0:\n",
    "        mod = 0\n",
    "    else:\n",
    "        mod = nx.algorithms.community.quality.modularity(G,partition)\n",
    "    title = title + \" Modularity = \" + str(np.round(mod,2))\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the network we'll use to illustrate the ideas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, pos = get_NCM_Figure3_14()\n",
    "show_partitions(G, \n",
    "                partition = [list(G.nodes),[]], \n",
    "                pos=pos,\n",
    "                title = \"Example Network\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectral Methods**\n",
    "\n",
    "We are using eigenvectors and eigenvalues to solve the spectral modularity cut problem. It's easy to blend terminology from the other problem in class that used eigenvectors and eignvalues: eigenvector centrality. \n",
    "\n",
    "The key distinction between the eigenvectors used in the spectral modularity cut problem and the eigenvectors used in the eigenvector centrality problem is the matrix.\n",
    "- The spectral cut problem uses an eigenvector from the modularity matrix $B$\n",
    "- The eigenvector centrality problem uses an eigenvector from the adjacency matrix $A$\n",
    "\n",
    "Let's compare these two matrices because their structures have a big impact on which eigenvectors are useful. Note that Networkx has a method that returns the modularity matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principal Eigenvector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## Cell 1 ##\n",
    "############\n",
    "A: NDArray = nx.adjacency_matrix(G, \n",
    "                                  nodelist=[node for node in sorted(G.nodes)]\n",
    "                                  ).toarray()  # nx.adjacency matrix returns a sparse matrix. Convert to array\n",
    "print(f\"Adjacency matrix is {A}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the eigenvector centrality problem, we wanted all vertices to have non-negative centrality. When the graph is connected, the Perron Frobenious theorem guaranteed that the eigenvalue with highest modulus corresponded to an eigenvector with all non-negative values. We wrote a function that found that eigenvector and eigenvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## Cell 2 ##\n",
    "############\n",
    "def get_principal_eigen(M: np.array) -> Tuple[float, NDArray]:\n",
    "    # Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(M)\n",
    "\n",
    "    # Find the index of the principal eigenvalue (the largest eigenvalue)\n",
    "    principal_eigenvalue_index = np.argmax(eigenvalues)\n",
    "\n",
    "    # Get the principal eigenvalue\n",
    "    principal_eigenvalue = eigenvalues[principal_eigenvalue_index]\n",
    "\n",
    "    # Get the principal eigenvector\n",
    "    principal_eigenvector = eigenvectors[:, principal_eigenvalue_index]\n",
    "    return principal_eigenvalue, principal_eigenvector\n",
    "\n",
    "principal_eigenvalue, principal_eigenvector = get_principal_eigen(A)\n",
    "print(f\"The principal eigenvalue of A is {np.round(principal_eigenvalue,2)}\")\n",
    "print(f\"The principal eigenvector of A is\\n   {np.round(principal_eigenvector,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are all the values of the principal eigenvector non-negative?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## Cell 3 ##\n",
    "############\n",
    "\n",
    "B: NDArray = nx.modularity_matrix(G, \n",
    "                                  nodelist=[node for node in sorted(G.nodes)])\n",
    "print(f\"Modularity matrix is\\n{B}\")\n",
    "\n",
    "\n",
    "print(B[0,:]) # First row\n",
    "print(f\"There are {len(G.edges)} edges in the network\")\n",
    "print(f\"Matrix entry (0,0) = 0- (k_0 k_0)/2m = {-2*2/(2*len(G.edges))}\")\n",
    "print(f\"Matrix entry (0,1) = 1- (k_0 k_1)/2m = {1-2*2/(2*len(G.edges))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the modularity matrix has both positive and negative values, but the adjacency matrix has only positive values. This difference between the elements of the matrices has an important impact on the eigenvectors. Before discussing what the impact is, let's do a quick review of why the modularity matrix has both positive and negative values.\n",
    "\n",
    "Recall that the modularity matrix is defined as\n",
    "\n",
    "$$ B_{ij} = A_{ij} - \\frac{k_ik_j}{2m}$$\n",
    "\n",
    "Let's look at the first two entries in the top row of the modularity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is negative, which makes sense in terms of the definition of the modularity matrix because \n",
    "- $A_{0,0} = 0$ (no self loops), and \n",
    "- $k_0=2$ which means that $\\frac{k_0 k_0}{2m} = (2*2)/(2*17) = 0.1176$.\n",
    "\n",
    "The second element is positive, which is\n",
    "- $A_{0,1} = 1$ since node 0 is connected to node 1\n",
    "- $k_0 = 2$ and $k_1= 2$, which means that $\\frac{k_0 k_1}{2m} = (2*2)/(2*17) = 0.1176$.\n",
    "- The difference is $0.8824$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we try to try to find the principal eigenvector for the modularity matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "## Cell 4 ##\n",
    "############\n",
    "principal_eigenvalue, principal_eigenvector = get_principal_eigen(B)\n",
    "print(f\"The principal eigenvalue of B is {np.round(principal_eigenvalue,2)}\")\n",
    "print(f\"The principal eigenvector of B is\\n   {np.round(principal_eigenvector,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The eigenvector has both positive and negative values. Why aren't all the values of the eigenvector positive? Because the modularity matrix $B$ does not satisfy the conditions of the Perron-Frobenius theorem. This means that the terms _principal eigenvalue_ and _principal eigenvector_ are not defined for the modularity matrix. We need a different definition. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leading Eigenvector**\n",
    "\n",
    "Recall that we are trying to maximize ${\\mathbf x}^TB{\\mathbf x}$ (subject to the constraint on ${\\mathbf x}$ that keeps these values from being too high). Let's plug in the fact that ${\\mathbf x}$ is an eigenvector. Then the solution that maximizes ${\\mathbf x}^TB{\\mathbf x}$ can be written as $\\lambda{\\mathbf x}$ (taking advantage of the fact that $B$ is symmetric). The maximum therefore occurs when $\\lambda$ is the largest positive eigenvalue.  (Caution: Microsoft Copilot halucinated an incorrect interpretation of which eigenvalue is best.)\n",
    "\n",
    "The largest positive eigenvalue has a name. It is called the _leading eigenvector_. \n",
    "\n",
    "Note that we've been finding partitions only of undirected networks. Consequently, $B=B^T$, which means that all the eigenvalues of $B$ are real. (Later on in the class, we'll probably discuss the theorem that states that the eigenvalues of a real symmetric matrix are real.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the eigenvalues and eigenvectors of $B$ to get a sense of their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[vals, vecs] = np.linalg.eig(B)\n",
    "print(f\"eigenvalues of B are\\n {np.round(vals,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the eigenvector that corresponds to the leading eigenvalue. (Code from Copilot.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leading_eigenvector(G: nx.Graph\n",
    "                            ) -> Tuple[float, List[float]]:\n",
    "    B: NDArray = nx.modularity_matrix(G)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(B)\n",
    "    largest_eigenvalue_index = np.argmax(eigenvalues)\n",
    "    largest_eigenvalue = eigenvalues[largest_eigenvalue_index]\n",
    "    leading_eigenvector = eigenvectors[:, largest_eigenvalue_index]\n",
    "    return largest_eigenvalue, leading_eigenvector\n",
    "\n",
    "largest_eigenvalue, leading_eigenvector = get_leading_eigenvector(G)\n",
    "print(\"Largest Eigenvalue:\", np.round(largest_eigenvalue,2))\n",
    "print(\"Leading Eigenvector:\", np.round(leading_eigenvector,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rule we derived in class for turning the values in the leading eigenvector into the $s_i$ values is:\n",
    "\n",
    "$$ \n",
    "s_i = \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "        1 & {\\rm if\\ } x_i  \\geq 0 \\\\\n",
    "        0 & {\\rm otherwise}\n",
    "    \\end{array}\n",
    "\\right. \n",
    "$$\n",
    "\n",
    "Vertices are therefore assigned to a shore using\n",
    "\n",
    "$$ v_i \\in \\left\\{ \n",
    "    \\begin{array}{cl}\n",
    "        {\\rm shore\\_1} & {\\rm if\\ } x_i \\geq 0 \\\\\n",
    "        {\\rm shore\\_2} & {\\rm otherwise}\n",
    "    \\end{array}\n",
    "\\right. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shores_from_eigenvector(x):\n",
    "    shore1 = set()\n",
    "    shore2 = set()\n",
    "    for node in G.nodes:\n",
    "        if x[node] >= 0: \n",
    "            shore1.add(node)\n",
    "        else: \n",
    "            shore2.add(node)\n",
    "    return [shore1, shore2]\n",
    "partitions = get_shores_from_eigenvector(leading_eigenvector)\n",
    "show_partitions(G, partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the code to find the partition for a path graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.path_graph(5)\n",
    "largest_eigenvalue, leading_eigenvector = get_leading_eigenvector(G)\n",
    "partitions = get_shores_from_eigenvector(leading_eigenvector)\n",
    "show_partitions(G, partitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now repeat for the karate club graph. Begin with some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "largest_eigenvalue, leading_eigenvector = get_leading_eigenvector(G)\n",
    "partitions = get_shores_from_eigenvector(leading_eigenvector)\n",
    "show_partitions(G, partitions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
